<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Setting up your first distributed private storage network on IPFS: Part 2</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Setting up your first distributed private storage network on IPFS: Part 2</h1>
</header>
<section data-field="subtitle" class="p-summary">
Welcome back to the IPFS private network series. If you are wondering why I am welcoming you back, then you should take a look at this…
</section>
<section data-field="body" class="e-content">
<section name="75b4" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="8bd6" id="8bd6" class="graf graf--h3 graf--leading graf--title">Setting up your first distributed private storage network on IPFS: Part 2</h3><figure name="fd63" id="fd63" class="graf graf--figure graf-after--h3"><div class="aspectRatioPlaceholder is-locked" style="max-width: 640px; max-height: 256px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 40%;"></div><img class="graf-image" data-image-id="1*ns6pbkuJN3vFMJSqDLDVww.png" data-width="640" data-height="256" src="https://cdn-images-1.medium.com/max/800/1*ns6pbkuJN3vFMJSqDLDVww.png"></div><figcaption class="imageCaption">Bait for IPFS lovers</figcaption></figure><p name="2e91" id="2e91" class="graf graf--p graf-after--figure">Welcome back to the IPFS private network series. If you are wondering why I am welcoming you back, then you should take a look at this previous post..</p><div name="073b" id="073b" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-1-a6ff15222b90" data-href="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-1-a6ff15222b90" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-1-a6ff15222b90"><strong class="markup--strong markup--mixtapeEmbed-strong">Setting up your first distributed private storage network on IPFS: Part 1</strong><br><em class="markup--em markup--mixtapeEmbed-em">IPFS Private Storage Network Series</em>medium.com</a><a href="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-1-a6ff15222b90" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="57bf7572c8726313262cbb6783cd8e30" data-thumbnail-img-id="1*ns6pbkuJN3vFMJSqDLDVww.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*ns6pbkuJN3vFMJSqDLDVww.png);"></a></div><p name="12fd" id="12fd" class="graf graf--p graf-after--mixtapeEmbed">Now assuming you have read the above post, lets get started where we left last time.</p><h3 name="8703" id="8703" class="graf graf--h3 graf-after--p">Static cluster membership considerations</h3><p name="635d" id="635d" class="graf graf--p graf-after--h3">We call a static cluster, that in which the set of <code class="markup--code markup--p-code">cluster.peers</code> is fixed, where &quot;peer add&quot;/&quot;peer rm&quot;/bootstrapping operations don&#39;t happen (at least normally) and where every cluster member is expected to be running all the time.</p><p name="7c77" id="7c77" class="graf graf--p graf-after--p">Static clusters are a way to run ipfs-cluster in a stable fashion, since the membership of the consensus remains unchanged, they don’t suffer the dangers of dynamic peer sets, where it is important that operations modifying the peer set succeed for every cluster member.</p><p name="487f" id="487f" class="graf graf--p graf-after--p">Static clusters expect every member peer to be up and responding. Otherwise, the Leader will detect missing heartbeats and start logging errors. When a peer is not responding, ipfs-cluster will detect that a peer is down and re-allocate any content pinned by that peer to other peers. ipfs-cluster will still work as long as there is a Leader (half of the peers are still running). In the case of a network split, or if a majority of nodes is down, cluster will be unable to commit any operations the the log and thus, it’s functionality will be limited to read operations.</p><h3 name="aed0" id="aed0" class="graf graf--h3 graf-after--p">Dynamic cluster membership considerations</h3><p name="0739" id="0739" class="graf graf--p graf-after--h3">We call a dynamic cluster, that in which the set of <code class="markup--code markup--p-code">cluster.peers</code> changes. Nodes are bootstrapped to existing cluster peers (<code class="markup--code markup--p-code">cluster.bootstrap</code> option), the &quot;peer rm&quot; operation is used and/or the <code class="markup--code markup--p-code">cluster.leave_on_shutdown</code> configuration option is enabled. This option allows a node to abandon the consensus membership when shutting down. Thus reducing the cluster size by one.</p><p name="c57e" id="c57e" class="graf graf--p graf-after--p">Dynamic clusters allow greater flexibility at the cost of stablity. Leave and, specially, join operations are tricky as they change the consensus membership. They are likely to fail in unhealthy clusters. All operations modifying the peerset require an elected and working leader. Note that peerset modifications may also trigger pin re-allocations if any of the pins from the departing cluster crosses below the <code class="markup--code markup--p-code">replication_factor_min</code> threshold.</p><p name="706d" id="706d" class="graf graf--p graf-after--p">Peers joining an existing cluster should not have any consensus state (contents in <code class="markup--code markup--p-code">./ipfs-cluster/ipfs-cluster-data</code>). Peers leaving a cluster are not expected to re-join it with stale consensus data. For this reason, the consensus data folder is renamed when a peer leaves the current cluster. For example, <code class="markup--code markup--p-code">ipfs-cluster-data</code> becomes <code class="markup--code markup--p-code">ipfs-cluster-data.old.0</code>and so on. Currently, up to 5 copies of the cluster data will be left around, with <code class="markup--code markup--p-code">old.0</code> being the most recent, and <code class="markup--code markup--p-code">old.4</code> the oldest.</p><p name="2ea8" id="2ea8" class="graf graf--p graf-after--p">When a peer leaves or is removed, any existing peers will be saved as <code class="markup--code markup--p-code">bootstrap</code> peers, so that it is easier to re-join the cluster by simply re-launching it. Since the state has been cleaned, the peer will be able to re-join and fetch the latest state cleanly. See &quot;The consensus algorithm&quot; and the &quot;Starting your cluster peers&quot; sections <a href="https://medium.com/@vaibhavsaini_67863/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-1-a6ff15222b90" data-href="https://medium.com/@vaibhavsaini_67863/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-1-a6ff15222b90" class="markup--anchor markup--p-anchor" target="_blank">here</a> for more information.</p><p name="eaf6" id="eaf6" class="graf graf--p graf-after--p">This does not mean that there are not possibilities of somehow getting a broken cluster membership. The best way to diagnose it and fix it is to:</p><ul class="postList"><li name="ff59" id="ff59" class="graf graf--li graf-after--p">Select a healthy node</li><li name="a798" id="a798" class="graf graf--li graf-after--li">Run <code class="markup--code markup--li-code">ipfs-cluster-ctl peers ls</code></li><li name="aa08" id="aa08" class="graf graf--li graf-after--li">Examine carefully the results and any errors</li><li name="eb62" id="eb62" class="graf graf--li graf-after--li">Run <code class="markup--code markup--li-code">ipfs-cluster-ctl peers rm &lt;peer in error&gt;</code> for every peer not responding</li><li name="22a5" id="22a5" class="graf graf--li graf-after--li">If the peer count is different depending on the peers responding, remove those peers too. Once stopped, remove the consensus data folder and bootstrap them to a healthy cluster peer. Always make sure to keep 1/2+1 peers alive and healthy.</li><li name="db21" id="db21" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">ipfs-cluster-ctl --enc=json peers ls</code> provides additional useful information, like the list of peers for every responding peer.</li><li name="a677" id="a677" class="graf graf--li graf-after--li">In cases were leadership has been lost beyond solution (meaning faulty peers cannot be removed), it is best to stop all peers and restore the state from the backup (currently, a manual operation).</li></ul><p name="7d4f" id="7d4f" class="graf graf--p graf-after--li">Remember: if you have a problematic cluster peer trying to join an otherwise working cluster, the safest way is to rename the <code class="markup--code markup--p-code">ipfs-cluster-data</code> folder (keeping it as backup) and to set the correct <code class="markup--code markup--p-code">bootstrap</code>. The consensus algorithm will then resend the state from scratch.</p><p name="c0e7" id="c0e7" class="graf graf--p graf-after--p">ipfs-cluster will fail to start if <code class="markup--code markup--p-code">cluster.peers</code> do not match the current Raft peerset. If the current Raft peerset is correct, you can manually update <code class="markup--code markup--p-code">cluster.peers</code>. Otherwise, it is easier to clean and bootstrap.</p><p name="31a4" id="31a4" class="graf graf--p graf-after--p">Finally, note that when bootstrapping a peer to an existing cluster, the new peer must be configured with the same <code class="markup--code markup--p-code">cluster.secret</code> as the rest of the cluster.</p><h3 name="c5bd" id="c5bd" class="graf graf--h3 graf-after--p">Pinning an item</h3><p name="474f" id="474f" class="graf graf--p graf-after--h3"><code class="markup--code markup--p-code">ipfs-cluster-ctl pin add &lt;cid&gt;</code> will tell ipfs-cluster to pin (or re-pin) a CID.</p><p name="daf5" id="daf5" class="graf graf--p graf-after--p">This involves:</p><ul class="postList"><li name="072d" id="072d" class="graf graf--li graf-after--p">Deciding which peers will be allocated the CID (that is, which cluster peers will ask ipfs to pin the CID). This depends on the replication factor (min and max) and the allocation strategy (more details below).</li><li name="3b61" id="3b61" class="graf graf--li graf-after--li">Forwarding the pin request to the Raft Leader.</li><li name="edaa" id="edaa" class="graf graf--li graf-after--li">Commiting the pin entry to the log.</li><li name="01c1" id="01c1" class="graf graf--li graf-after--li"><em class="markup--em markup--li-em">At this point, a success/failure is returned to the user, but ipfs-cluster has more things to do.</em></li><li name="bddb" id="bddb" class="graf graf--li graf-after--li">Receiving the log update and modifying the <em class="markup--em markup--li-em">shared state</em> accordingly.</li><li name="7a91" id="7a91" class="graf graf--li graf-after--li">Updating the local state.</li><li name="f652" id="f652" class="graf graf--li graf-after--li">If the peer has been allocated the content, then:</li><li name="5221" id="5221" class="graf graf--li graf-after--li">Queueing the pin request and setting the pin status to <code class="markup--code markup--li-code">PINNING</code>.</li><li name="0883" id="0883" class="graf graf--li graf-after--li">Triggering a pin operation</li><li name="49db" id="49db" class="graf graf--li graf-after--li">Waiting until it completes and setting the pin status to <code class="markup--code markup--li-code">PINNED</code>.</li></ul><p name="ffa3" id="ffa3" class="graf graf--p graf-after--li">Errors in the first part of the process (before the entry is commited) will be returned to the user and the whole operation is aborted. Errors in the second part of the process will result in pins with an status of <code class="markup--code markup--p-code">PIN_ERROR</code>.</p><p name="bc9e" id="bc9e" class="graf graf--p graf-after--p">Deciding where a CID will be pinned (which IPFS daemon will store it — receive the allocation) is a complex process. In order to decide, all available peers (those reporting valid/non-expired metrics) are sorted by the <code class="markup--code markup--p-code">allocator</code> component, depending on the value of their metrics. These values are provided by the configured <code class="markup--code markup--p-code">informer</code>. If a CID is already allocated to some peers (in the case of a re-pinning operation), those allocations are kept.</p><p name="01b8" id="01b8" class="graf graf--p graf-after--p">New allocations are only provided when the allocation factor (healthy peers holding the CID) is below the <code class="markup--code markup--p-code">replication_factor_min</code> threshold. In those cases, the new allocations (along with the existing valid ones), will attempt to total as much as <code class="markup--code markup--p-code">replication_factor_max</code>. When the allocation factor of a CID is within the margins indicated by the replication factors, no action is taken. The value &quot;-1&quot; and <code class="markup--code markup--p-code">replication_factor_min</code> and <code class="markup--code markup--p-code">replication_factor_max</code> indicates a &quot;replicate everywhere&quot; mode, where every peer will pin the CID.</p><p name="23a2" id="23a2" class="graf graf--p graf-after--p">Default replication factors are specified in the configuration, but every Pin object carries them associated to its own entry in the <em class="markup--em markup--p-em">shared state</em>. Changing the replication factor of existing pins requires re-pinning them (it does not suffice to change the configuration). You can always check the details of a pin, including its replication factors, using <code class="markup--code markup--p-code">ipfs-cluster-ctl pin ls &lt;cid&gt;</code>. You can use <code class="markup--code markup--p-code">ipfs-cluster-ctl pin add &lt;cid&gt;</code> to re-pin at any time with different replication factors. But note that the new pin will only be commited if it differs from the existing one in the way specified in the paragraph above.</p><p name="69e0" id="69e0" class="graf graf--p graf-after--p">In order to check the status of a pin, use <code class="markup--code markup--p-code">ipfs-cluster-ctl status &lt;cid&gt;</code>. Retries for pins in error state can be triggered with <code class="markup--code markup--p-code">ipfs-cluster-ctl recover &lt;cid&gt;</code>.</p><p name="d23d" id="d23d" class="graf graf--p graf-after--p">The reason pins (and unpin) requests are queued is because ipfs only performs one pin at a time, while any other requests are hanging in the meantime. All in all, pinning items which are unavailable in the network may create significants bottlenecks (this is a problem that comes from ipfs), as the pin request takes very long to time out. Facing this problem involves restarting the ipfs node.</p><h3 name="c995" id="c995" class="graf graf--h3 graf-after--p">Unpinning an item</h3><p name="619a" id="619a" class="graf graf--p graf-after--h3"><code class="markup--code markup--p-code">ipfs-cluster-ctl pin rm &lt;cid&gt;</code> will tell ipfs-cluster to unpin a CID.</p><p name="3612" id="3612" class="graf graf--p graf-after--p">The process is very similar to the “Pinning an item” described above. Removed pins are wiped from the shared and local states. When requesting the local <code class="markup--code markup--p-code">status</code> for a given CID, it will show as <code class="markup--code markup--p-code">UNPINNED</code>. Errors will be reflected as <code class="markup--code markup--p-code">UNPIN_ERROR</code> in the pin local status.</p><h3 name="e950" id="e950" class="graf graf--h3 graf-after--p">Cluster monitoring and pin failover</h3><p name="7f72" id="7f72" class="graf graf--p graf-after--h3">ipfs-cluster includes a basic monitoring component which gathers metrics and triggers alerts when a metric is no longer renewed. There are currently two types of metrics:</p><ul class="postList"><li name="5b35" id="5b35" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">informer</code> metrics are used to decide on allocations when a pin request arrives. Different &quot;informers&quot; can be configured. The default is the disk informer using the <code class="markup--code markup--li-code">freespace</code> metric.</li><li name="34b6" id="34b6" class="graf graf--li graf-after--li">a <code class="markup--code markup--li-code">ping</code> metric is used to signal that a peer is alive.</li></ul><p name="e559" id="e559" class="graf graf--p graf-after--li">Every metric carries a Time-To-Live associated with it. This TTL can be configued in the <code class="markup--code markup--p-code">informers</code> configuration section. The <code class="markup--code markup--p-code">ping</code> metric TTL is determined by the <code class="markup--code markup--p-code">cluster.monitoring_ping_interval</code>, and is equal to 2x its value.</p><p name="8225" id="8225" class="graf graf--p graf-after--p">Every ipfs-cluster peers push metrics to the cluster Leader regularly. This happens TTL/2 intervals for the <code class="markup--code markup--p-code">informer</code> metrics and in <code class="markup--code markup--p-code">cluster.monitoring_ping_interval</code> for the <code class="markup--code markup--p-code">ping</code> metrics.</p><p name="983e" id="983e" class="graf graf--p graf-after--p">When a metric for an existing cluster peer stops arriving and previous metrics have outlived their Time-To-Live, the monitoring component triggers an alert for that metric. <code class="markup--code markup--p-code">monbasic.check_interval</code> determines how often the monitoring component checks for expired TTLs and sends these alerts. If you wish to detect expired metrics more quickly, decrease this interval. Otherwise, increase it.</p><p name="8cd9" id="8cd9" class="graf graf--p graf-after--p">ipfs-cluster will react to <code class="markup--code markup--p-code">ping</code> metrics alerts by searching for pins allocated to the alerting peer and triggering re-pinning requests for them. These re-pinning requests may result in re-allocations if the the CID&#39;s allocation factor crosses the <code class="markup--code markup--p-code">replication_factor_min</code> boundary. Otherwise, the current allocations are maintained.</p><p name="fbb3" id="fbb3" class="graf graf--p graf-after--p">The monitoring and failover system in cluster is very basic and requires improvements. Failover is likely to not work properly when several nodes go offline at once (specially if the current Leader is affected). Manual re-pinning can be triggered with <code class="markup--code markup--p-code">ipfs-cluster-ctl pin &lt;cid&gt;</code>. <code class="markup--code markup--p-code">ipfs-cluster-ctl pin ls &lt;CID&gt;</code> can be used to find out the current list of peers allocated to a CID.</p><h3 name="613b" id="613b" class="graf graf--h3 graf-after--p">Using the IPFS-proxy</h3><p name="a44a" id="a44a" class="graf graf--p graf-after--h3">ipfs-cluster provides an proxy to ipfs (which by default listens on <code class="markup--code markup--p-code">/ip4/127.0.0.1/tcp/9095</code>). This allows ipfs-cluster to behave as if it was an ipfs node. It achieves this by intercepting the following requests:</p><ul class="postList"><li name="c6e1" id="c6e1" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">/add</code>: the proxy adds the content to the local ipfs daemon and pins the resulting hash[es] in ipfs-cluster.</li><li name="841e" id="841e" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">/pin/add</code>: the proxy pins the given CID in ipfs-cluster.</li><li name="018d" id="018d" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">/pin/rm</code>: the proxy unpins the given CID from ipfs-cluster.</li><li name="e9de" id="e9de" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">/pin/ls</code>: the proxy lists the pinned items in ipfs-cluster.</li></ul><p name="2db3" id="2db3" class="graf graf--p graf-after--li">Responses from the proxy mimic ipfs daemon responses. This allows to use ipfs-cluster with the <code class="markup--code markup--p-code">ipfs</code> CLI as the following examples show:</p><ul class="postList"><li name="4046" id="4046" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">ipfs --api /ip4/127.0.0.1/tcp/9095 pin add &lt;cid&gt;</code></li><li name="daec" id="daec" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">ipfs --api /ip4/127.0.0.1/tcp/9095 add myfile.txt</code></li><li name="31df" id="31df" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">ipfs --api /ip4/127.0.0.1/tcp/9095 pin rm &lt;cid&gt;</code></li><li name="6ac2" id="6ac2" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">ipfs --api /ip4/127.0.0.1/tcp/9095 pin ls</code></li></ul><p name="14cd" id="14cd" class="graf graf--p graf-after--li">Any other requests are directly forwarded to the ipfs daemon and responses and sent back from it.</p><p name="f571" id="f571" class="graf graf--p graf-after--p graf--trailing">Intercepted endpoints aim to mimic the format and response code from ipfs, but they may lack headers. If you encounter a problem where something works with ipfs but not with cluster, open an issue.</p></div></div></section><section name="f9ec" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="256d" id="256d" class="graf graf--p graf--leading">I am sure you are exhausted by now, take a break. If you want to continue further the proceed to below post(explaining one more type of cluster, security of clusters and debugging IPFS cluster).</p><div name="18ca" id="18ca" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.com/@vaibhavsaini_67863/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-3-48851488b8d8" data-href="https://medium.com/@vaibhavsaini_67863/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-3-48851488b8d8" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/@vaibhavsaini_67863/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-3-48851488b8d8"><strong class="markup--strong markup--mixtapeEmbed-strong">Setting up your first distributed private storage network on IPFS: Part 3</strong><br><em class="markup--em markup--mixtapeEmbed-em">Setting up your first distributed private storage network on IPFS: Part 3. Welcome back to the IPFS private network…</em>medium.com</a><a href="https://medium.com/@vaibhavsaini_67863/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-3-48851488b8d8" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="2db5586646f9cd5c0e95699c7190a4f8" data-thumbnail-img-id="0*zeKATAVimFm6BDbq." style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/0*zeKATAVimFm6BDbq.);"></a></div><h4 name="92bb" id="92bb" class="graf graf--h4 graf-after--mixtapeEmbed">Learned something? Click the 👏 to say “thanks!” and help others find this article.</h4><p name="1910" id="1910" class="graf graf--p graf-after--h4"><em class="markup--em markup--p-em">Hold down the clap button if you liked the content! It helps me gain exposure .</em></p><p name="c25f" id="c25f" class="graf graf--p graf-after--p">Want to learn more? Checkout my previous articles.</p><div name="f015" id="f015" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://hackernoon.com/quantum-computing-is-it-the-end-of-blockchain-9ce4a9664720" data-href="https://hackernoon.com/quantum-computing-is-it-the-end-of-blockchain-9ce4a9664720" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://hackernoon.com/quantum-computing-is-it-the-end-of-blockchain-9ce4a9664720"><strong class="markup--strong markup--mixtapeEmbed-strong">Quantum Computing: Is it the end of blockchain?</strong><br><em class="markup--em markup--mixtapeEmbed-em">Experts are suggesting quantum computing may render blockchain obsolete. As the tech giants such as Google and IBM are…</em>hackernoon.com</a><a href="https://hackernoon.com/quantum-computing-is-it-the-end-of-blockchain-9ce4a9664720" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="0621fabdce44c9b934053355ae4634b2" data-thumbnail-img-id="1*8JzfIkH5mEr0TqAhSMbJkA.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*8JzfIkH5mEr0TqAhSMbJkA.png);"></a></div><div name="cb2a" id="cb2a" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://hackernoon.com/eos-101-getting-started-with-eos-part-1-ab0324c233e0" data-href="https://hackernoon.com/eos-101-getting-started-with-eos-part-1-ab0324c233e0" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://hackernoon.com/eos-101-getting-started-with-eos-part-1-ab0324c233e0"><strong class="markup--strong markup--mixtapeEmbed-strong">EOS 101: Getting started with EOS, Part 1</strong><br><em class="markup--em markup--mixtapeEmbed-em">The only blockchain which has blocktime of less than a second: 0.5 sec!</em>hackernoon.com</a><a href="https://hackernoon.com/eos-101-getting-started-with-eos-part-1-ab0324c233e0" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="fd8747ef4c18e7ed85fa1f826a789f6f" data-thumbnail-img-id="1*_BKG3utRCovL4A9s78vEpA.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*_BKG3utRCovL4A9s78vEpA.png);"></a></div><div name="4ae6" id="4ae6" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://medium.com/coinmonks/13-sidechain-projects-every-blockchain-developer-should-know-about-804b65364107" data-href="https://medium.com/coinmonks/13-sidechain-projects-every-blockchain-developer-should-know-about-804b65364107" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/coinmonks/13-sidechain-projects-every-blockchain-developer-should-know-about-804b65364107"><strong class="markup--strong markup--mixtapeEmbed-strong">13 sidechain projects every blockchain developer should know about</strong><br><em class="markup--em markup--mixtapeEmbed-em">The whole world is going through the blockchain revolution. But wait…is this really what we dreamed of? Present…</em>medium.com</a><a href="https://medium.com/coinmonks/13-sidechain-projects-every-blockchain-developer-should-know-about-804b65364107" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="47a933f0a2a854e802a0df436c7a5c2c" data-thumbnail-img-id="1*0lBFcDwvD7ryBTJLSnzYdg.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*0lBFcDwvD7ryBTJLSnzYdg.png);"></a></div><div name="9c11" id="9c11" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-1-a6ff15222b90" data-href="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-1-a6ff15222b90" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-1-a6ff15222b90"><strong class="markup--strong markup--mixtapeEmbed-strong">Setting up your first distributed private storage network on IPFS: Part 1</strong><br><em class="markup--em markup--mixtapeEmbed-em">IPFS Private Storage Network Series</em>medium.com</a><a href="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-1-a6ff15222b90" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="57bf7572c8726313262cbb6783cd8e30" data-thumbnail-img-id="1*ns6pbkuJN3vFMJSqDLDVww.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*ns6pbkuJN3vFMJSqDLDVww.png);"></a></div><p name="c40b" id="c40b" class="graf graf--p graf-after--mixtapeEmbed"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Clap 50 times and follow me on Twitter: </em></strong><a href="https://twitter.com/itsmattward" data-href="https://twitter.com/itsmattward" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">@</em></strong></a><a href="https://twitter.com/vasa_develop" data-href="https://twitter.com/vasa_develop" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">vasa_develop</em></strong></a></p><figure name="3b69" id="3b69" class="graf graf--figure graf-after--p graf--trailing"><div class="aspectRatioPlaceholder is-locked" style="max-width: 250px; max-height: 250px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 100%;"></div><img class="graf-image" data-image-id="1*rSzC1HSUkD5Iwz-aXZT_8Q.gif" data-width="250" data-height="250" src="https://cdn-images-1.medium.com/max/800/1*rSzC1HSUkD5Iwz-aXZT_8Q.gif"></div></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@vaibhavsaini_67863" class="p-author h-card">vasa</a> on <a href="https://medium.com/p/4b6f96712bae"><time class="dt-published" datetime="2018-04-24T21:04:03.822Z">April 24, 2018</time></a>.</p><p><a href="https://medium.com/@vaibhavsaini_67863/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-2-4b6f96712bae" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 19, 2019.</p></footer></article></body></html>