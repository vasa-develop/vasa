<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Setting up your first distributed private storage network on IPFS: Part 1</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Setting up your first distributed private storage network on IPFS: Part 1</h1>
</header>
<section data-field="subtitle" class="p-summary">
IPFS Private Storage Network Series
</section>
<section data-field="body" class="e-content">
<section name="c28e" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="326a" id="326a" class="graf graf--h3 graf--leading graf--title">Setting up your first distributed private storage network on IPFS: Part 1</h3><figure name="0adf" id="0adf" class="graf graf--figure graf-after--h3"><div class="aspectRatioPlaceholder is-locked" style="max-width: 640px; max-height: 256px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 40%;"></div><img class="graf-image" data-image-id="1*ns6pbkuJN3vFMJSqDLDVww.png" data-width="640" data-height="256" src="https://cdn-images-1.medium.com/max/800/1*ns6pbkuJN3vFMJSqDLDVww.png"></div><figcaption class="imageCaption">Bait for IPFS lovers</figcaption></figure><h3 name="6c7b" id="6c7b" class="graf graf--h3 graf-after--figure">IPFS Private Storage Network Series</h3><p name="e258" id="e258" class="graf graf--p graf-after--h3">This post marks the first in a new IPFS series I am starting in an effort to provide some easy to read instructions covering topics I found online, particularly vast and hard to get started.</p><p name="9bab" id="9bab" class="graf graf--p graf-after--p">In this and next 2 posts we are only going to cover the basics of <em class="markup--em markup--p-em">IPFS cluster:</em> <em class="markup--em markup--p-em">Collective pinning and composition for IPFS. </em>But if you want to get your hands dirty, then jump to this post:</p><div name="4baa" id="4baa" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://hackernoon.com/setting-up-a-2-node-private-storage-network-on-ipfs-in-1-min-part-4-93ea41d4c551" data-href="https://hackernoon.com/setting-up-a-2-node-private-storage-network-on-ipfs-in-1-min-part-4-93ea41d4c551" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://hackernoon.com/setting-up-a-2-node-private-storage-network-on-ipfs-in-1-min-part-4-93ea41d4c551"><strong class="markup--strong markup--mixtapeEmbed-strong">Setting up a 2 node private storage network on IPFS in 1 min: Part 4</strong><br><em class="markup--em markup--mixtapeEmbed-em">In this post we are going to set up a 2 node IPFS storage network within 1 minute.</em>hackernoon.com</a><a href="https://hackernoon.com/setting-up-a-2-node-private-storage-network-on-ipfs-in-1-min-part-4-93ea41d4c551" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="262961ab0d0c7f871dfe1d98040dfb9d" data-thumbnail-img-id="1*ns6pbkuJN3vFMJSqDLDVww.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*ns6pbkuJN3vFMJSqDLDVww.png);"></a></div><p name="e615" id="e615" class="graf graf--p graf-after--mixtapeEmbed">Stay tuned for the next post.</p><p name="ce05" id="ce05" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Setting up a multi-node private storage network on IPFS: Part 5</em></strong></p><p name="5a55" id="5a55" class="graf graf--p graf-after--p">For now, lets get started.</p><h3 name="aa31" id="aa31" class="graf graf--h3 graf-after--p">IPFS Cluster</h3><h4 name="175e" id="175e" class="graf graf--h4 graf-after--h3">Applications</h4><p name="b038" id="b038" class="graf graf--p graf-after--h4"><em class="markup--em markup--p-em">IPFS cluster</em> consist of 2 main applications namely:</p><p name="aa06" id="aa06" class="graf graf--p graf-after--p"><code class="markup--code markup--p-code">ipfs-cluster-service</code> : for starting your cluster peer.</p><p name="6f51" id="6f51" class="graf graf--p graf-after--p"><code class="markup--code markup--p-code">ipfs-cluster-ctl</code> : for interacting with the cluster peer through various inbuilt APIs.</p><h4 name="eec4" id="eec4" class="graf graf--h4 graf-after--p">The consensus algorithm:</h4><p name="be16" id="be16" class="graf graf--p graf-after--h4">ipfs-cluster peers coordinate their state (the list of CIDs which are pinned, their peer allocations and replication factor) using a consensus algorithm called <a href="https://raft.github.io/" data-href="https://raft.github.io/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">Raft</a>. It is <strong class="markup--strong markup--p-strong">strongly recommended</strong> to see this <a href="http://thesecretlivesofdata.com/raft/" data-href="http://thesecretlivesofdata.com/raft/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">raft explanation</a> before proceeding.</p><p name="63bb" id="63bb" class="graf graf--p graf-after--p">Raft is used to commit log entries to a “distributed log” which every peer follows. Every “Pin” and “Unpin” requests are log entries in that log. When a peer receives a log “Pin” operation, it updates its local copy of the shared state to indicate that the CID is now pinned.</p><blockquote name="dfa1" id="dfa1" class="graf graf--blockquote graf-after--p">In order to work, Raft elects a cluster “Leader”, which is the only peer allowed to commit entries to the log. Thus, a Leader election can only succeed if at least half of the nodes are online. Log entries, and other parts of ipfs-cluster functionality (initialization, monitoring), can only happen when a Leader exists.</blockquote><p name="9969" id="9969" class="graf graf--p graf-after--blockquote">For example, a commit operation to the log is triggered with <code class="markup--code markup--p-code">ipfs-cluster-ctl pin add &lt;cid&gt;</code>. This will use the peer&#39;s API to send a Pin request. The peer will in turn forward the request to the cluster&#39;s Leader, which will perform the commit of the operation. This is explained in more detail in the &quot;Pinning an item&quot; section of this post.</p><div name="4e66" id="4e66" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-2-4b6f96712bae" data-href="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-2-4b6f96712bae" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-2-4b6f96712bae"><strong class="markup--strong markup--mixtapeEmbed-strong">Setting up your first distributed private storage network on IPFS: Part 2</strong><br><em class="markup--em markup--mixtapeEmbed-em">Welcome back to the IPFS private network series. If you are wondering why I am welcoming you back, then you should take…</em>medium.com</a><a href="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-2-4b6f96712bae" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="bbc54b1af98b7cbd0c1dc75290c70957" data-thumbnail-img-id="1*ns6pbkuJN3vFMJSqDLDVww.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*ns6pbkuJN3vFMJSqDLDVww.png);"></a></div><p name="651a" id="651a" class="graf graf--p graf-after--mixtapeEmbed">The “peer add” and “peer remove” operations also trigger log entries (internal to Raft) and depend too on a healthy consensus status. Modifying the cluster peers is a tricky operation because it requires informing every peer of the new peer’s multiaddresses. If a peer is down during this operation, the operation will fail, as otherwise that peer will not know how to contact the new member. Thus, it is recommended remove and bootstrap (these are the peers to which a new peer connects on boot up) any peer that is offline before making changes to the peerset.</p><p name="ddc9" id="ddc9" class="graf graf--p graf-after--p">By default, the consensus log data is backed in the <code class="markup--code markup--p-code">ipfs-cluster-data</code> subfolder, next to the main configuration file(see next section). This folder stores two types of information: the <strong class="markup--strong markup--p-strong">boltDB</strong> database storing the Raft log, and the state snapshots. Snapshots from the log are performed regularly when the log grows too big (see the <code class="markup--code markup--p-code">Starting your cluster peers </code>section below for options). When a peer is far behind in catching up with the log, Raft may opt to send a snapshot directly, rather than to send every log entry that makes up the state individually. This data is initialized on the first start of a cluster peer and maintained throughout its life. Removing or renaming the <code class="markup--code markup--p-code">ipfs-cluster-data</code> folder effectively resets the peer to a clean state. <strong class="markup--strong markup--p-strong">Only peers with a clean state should bootstrap to already running clusters</strong>.</p><p name="aeb2" id="aeb2" class="graf graf--p graf-after--p">When running a cluster peer, it is <strong class="markup--strong markup--p-strong">very important that the consensus data folder does not contain any data from a different cluster setup</strong>, or data from diverging logs. What this essentially means is that different Raft logs should not be mixed. Removing or renaming the <code class="markup--code markup--p-code">ipfs-cluster-data</code> folder, will clean all consensus data from the peer, but, as long as the rest of the cluster is running, it will recover last state upon start by fetching it from a different cluster peer.</p><p name="cf99" id="cf99" class="graf graf--p graf-after--p">On clean shutdowns, ipfs-cluster peers will save a human-readable state snapshot in <code class="markup--code markup--p-code">~/.ipfs-cluster/backups</code>, which can be used to inspect the last known state for that peer.</p><h4 name="2df8" id="2df8" class="graf graf--h4 graf-after--p">The configuration file</h4><p name="44df" id="44df" class="graf graf--p graf-after--h4">The ipfs-cluster configuration file is usually found at <code class="markup--code markup--p-code">~/.ipfs-cluster/service.json .</code>It holds all the configurable options for cluster and its different components. The configuration file is divided in sections. Each section represents a component. Each item inside the section represents an implementation of that component and contains specific options.</p><p name="a2cc" id="a2cc" class="graf graf--p graf-after--p">After <em class="markup--em markup--p-em">IPFS cluster installation</em> a default configuration file can be generated with <code class="markup--code markup--p-code">ipfs-cluster-service init</code> .It is recommended that you re-create the configuration file after an upgrade, to make sure that you are up to date with any new options.</p><p name="a9a2" id="a9a2" class="graf graf--p graf-after--p">The <code class="markup--code markup--p-code">cluster</code> section of the configuration stores a <code class="markup--code markup--p-code">secret</code>: a 32 byte (hex-encoded) key which <strong class="markup--strong markup--p-strong">must be shared by all cluster peers</strong>. Using an empty key has security implications (see the Security section <a href="https://medium.com/@vaibhavsaini_67863/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-3-48851488b8d8" data-href="https://medium.com/@vaibhavsaini_67863/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-3-48851488b8d8" class="markup--anchor markup--p-anchor" target="_blank">here</a>). Using <strong class="markup--strong markup--p-strong">different keys</strong> will prevent different peers from talking to each other.</p><p name="7979" id="7979" class="graf graf--p graf-after--p">Now, lets see the some sections of the configuration file. ( I have skipped some sections as the file is too big. You can see the full file with explanation <a href="https://github.com/vasa-develop/ipfs-private-network/blob/master/service.json" data-href="https://github.com/vasa-develop/ipfs-private-network/blob/master/service.json" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">here</a>)</p><h4 name="c839" id="c839" class="graf graf--h4 graf-after--p">cluster section (service.json)</h4><pre name="67a3" id="67a3" class="graf graf--pre graf-after--h4"><code class="markup--code markup--pre-code">{</code></pre><pre name="8993" id="8993" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">// main cluster component configuration<br>  &quot;cluster&quot;: {                                              </code></pre><pre name="9716" id="9716" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">// peer ID<br>    &quot;id&quot;: &quot;QmZyXksFG3vmLdAnmkXreMVZvxc4sNi1u21VxbRdNa2S1b&quot;,</code></pre><pre name="17e3" id="17e3" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">//node private key<br>    &quot;private_key&quot;: &quot;&lt;base64 representation of the key&gt;&quot;,</code></pre><pre name="5b0a" id="5b0a" class="graf graf--pre graf-after--pre">//above mentioned secret<br>    <code class="markup--code markup--pre-code">&quot;secret&quot;: &quot;&lt;32-bit hex encoded secret&gt;&quot;,</code></pre><pre name="ddfa" id="ddfa" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">// List of peers&#39; multiaddresses<br>    &quot;peers&quot;: [],                                            </code></pre><pre name="e066" id="e066" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">// List of bootstrap peers&#39; multiaddresses<br>    &quot;bootstrap&quot;: [],                                 <br>       <br>// Abandon cluster on shutdown<br>    &quot;leave_on_shutdown&quot;: false,</code></pre><pre name="f5de" id="f5de" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">// Cluster RPC listen<br>    &quot;listen_multiaddress&quot;: &quot;/ip4/0.0.0.0/tcp/9096&quot;,      <br>   <br>// Time between state syncs<br>    &quot;state_sync_interval&quot;: &quot;1m0s&quot;,                        <br>  <br>// Time between ipfs-state syncs<br>    &quot;ipfs_sync_interval&quot;: &quot;2m10s&quot;,</code></pre><pre name="e98a" id="e98a" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">// Replication factor minimum threshold. -1 == all<br>    &quot;replication_factor_min&quot;: -1,</code></pre><pre name="42eb" id="42eb" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">// Replication factor maximum threshold. -1 == all<br>    &quot;replication_factor_max&quot;: -1,</code></pre><pre name="62ac" id="62ac" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">// Time between alive-pings. See cluster monitoring section<br>    &quot;monitor_ping_interval&quot;: &quot;15s&quot;<br>  }</code></pre><p name="84d0" id="84d0" class="graf graf--p graf-after--pre">We will talk about other sections later in this post as we explore further.</p><h3 name="387a" id="387a" class="graf graf--h3 graf-after--p">Starting your cluster peers</h3><p name="b9d5" id="b9d5" class="graf graf--p graf-after--h3"><code class="markup--code markup--p-code">ipfs-cluster-service</code> will launch your cluster peer. If you have not configured any <code class="markup--code markup--p-code">cluster.peers</code> in the configuration, nor any <code class="markup--code markup--p-code">cluster.bootstrap</code> addresses, a single-peer cluster will be launched.</p><p name="cf85" id="cf85" class="graf graf--p graf-after--p">When filling in <code class="markup--code markup--p-code">peers</code> with some other peers&#39; listening multiaddresses (i.e. <code class="markup--code markup--p-code">/ip4/192.168.1.103/tcp/9096/ipfs/QmQHKLBXfS7hf8o2acj7FGADoJDLat3UazucbHrgxqisim</code>), the peer will expect to be part of a cluster with the given <code class="markup--code markup--p-code">peers</code>. On boot, it will wait to learn who is the leader (see <code class="markup--code markup--p-code">raft.wait_for_leader_timeout</code>option below ) and sync it&#39;s internal state up to the last known state before becoming <code class="markup--code markup--p-code">ready</code>.</p><h4 name="9bbd" id="9bbd" class="graf graf--h4 graf-after--p">consensus section (service.json)</h4><pre name="e23c" id="e23c" class="graf graf--pre graf-after--h4"><code class="markup--code markup--pre-code">&quot;consensus&quot;: {<br>    &quot;raft&quot;: {</code></pre><pre name="598f" id="598f" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">// How long to wait for a leader when there is none<br>      &quot;wait_for_leader_timeout&quot;: &quot;15s&quot;,            </code></pre><pre name="b24b" id="b24b" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">// How long to wait before timing out a network operation<br>      &quot;network_timeout&quot;: &quot;10s&quot;,                             </code></pre><pre name="cd5b" id="cd5b" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">// How many retries should we make before giving up on a commit failure<br>      &quot;commit_retries&quot;: 1,                         </code></pre><pre name="e497" id="e497" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">// How long to wait between commit retries         <br>      &quot;commit_retry_delay&quot;: &quot;200ms&quot;,  </code></pre><pre name="008b" id="008b" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">// Here and below: Raft options.                      <br>      &quot;heartbeat_timeout&quot;: &quot;1s&quot;,        </code></pre><pre name="bc49" id="bc49" class="graf graf--pre graf-after--pre"><code class="markup--code markup--pre-code">// See https://godoc.org/github.com/hashicorp/raft#Config                    <br>      &quot;election_timeout&quot;: &quot;1s&quot;,    <br>                        <br>      &quot;commit_timeout&quot;: &quot;50ms&quot;,<br>      &quot;max_append_entries&quot;: 64,<br>      &quot;trailing_logs&quot;: 10240,<br>      &quot;snapshot_interval&quot;: &quot;2m0s&quot;,<br>      &quot;snapshot_threshold&quot;: 8192,<br>      &quot;leader_lease_timeout&quot;: &quot;500ms&quot;<br>    }<br>  }</code></pre><p name="8ad7" id="8ad7" class="graf graf--p graf-after--pre">If you are using the <code class="markup--code markup--p-code">peers</code> configuration value, then it is very important that the <code class="markup--code markup--p-code">peers</code> configuration value in all cluster members is the same for all peers: it should contain the multiaddresses for the other peers in the cluster. It may contain a peer&#39;s own multiaddress too (but it will be removed automatically). If <code class="markup--code markup--p-code">peers</code> is not correct for all peer members, your node might not start or misbehave in not obvious ways (due to problem in reaching consensus).</p><p name="d562" id="d562" class="graf graf--p graf-after--p">You are expected to start the majority of the nodes at the same time when using this method(for operating with multiple peers simultaneously you can use <a href="https://github.com/ipfs/iptb" data-href="https://github.com/ipfs/iptb" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">this tool</a>). If half of them are not started, they will fail to elect a cluster leader before <code class="markup--code markup--p-code">raft.wait_for_leader_timeout</code>. Then they will shut themselves down. If there are peers missing, the cluster will not be in a healthy state (error messages will be displayed). The cluster will operate, as long as a majority of peers is up.</p><p name="7756" id="7756" class="graf graf--p graf-after--p">Alternatively, you can use the <code class="markup--code markup--p-code">bootstrap</code> variable to provide one or several bootstrap peers. In short, bootstrapping will use the given peer to request the list of cluster peers and fill-in the <code class="markup--code markup--p-code">peers</code> variable automatically. The bootstrapped peer will be, in turn, added to the cluster and made known to every other existing (and connected peer). <strong class="markup--strong markup--p-strong">You can also launch several peers at once, as long as they are bootstrapping from the same already-running-peer</strong>. The <code class="markup--code markup--p-code">--bootstrap</code> flag allows to provide a bootsrapping peer directly when calling <code class="markup--code markup--p-code">ipfs-cluster-service</code>.</p><p name="63fa" id="63fa" class="graf graf--p graf-after--p">Use the <code class="markup--code markup--p-code">bootstrap</code> method <strong class="markup--strong markup--p-strong">only when the rest of the cluster is healthy and all current participating peers are running</strong>. If you need to, remove any unhealthy peers with <code class="markup--code markup--p-code">ipfs-cluster-ctl peers rm &lt;pid&gt;</code>. Bootstrapping peers should be in a <code class="markup--code markup--p-code">clean</code>state, that is, with no previous raft-data loaded. If they are not, remove or rename the <code class="markup--code markup--p-code">~/.ipfs-cluster/ipfs-cluster-data</code>folder.</p><p name="e4d7" id="e4d7" class="graf graf--p graf-after--p">Once a cluster is up, peers are expected to run continuously. You may need to stop a peer, or it may die due to external reasons. The restart-behaviour will depend on whether the peer has left the consensus:</p><ul class="postList"><li name="292b" id="292b" class="graf graf--li graf-after--p">The <em class="markup--em markup--li-em">default</em> case — peer has not been removed and <code class="markup--code markup--li-code">cluster.leave_on_shutdown</code> is <code class="markup--code markup--li-code">false</code>: in this case the peer has not left the consensus peerset, and you may start the peer again normally. Do not manually update <code class="markup--code markup--li-code">cluster.peers</code>, even if other peers have been removed from the cluster.</li><li name="28ab" id="28ab" class="graf graf--li graf-after--li">The <em class="markup--em markup--li-em">left the cluster</em> case — peer has been manually removed or <code class="markup--code markup--li-code">cluster.leave_on_shutdown</code> is <code class="markup--code markup--li-code">true</code>: in this case, unless the peer died, it has probably been removed from the consensus (you can check if it&#39;s missing from <code class="markup--code markup--li-code">ipfs-cluster-ctl peers ls</code> on a running peer). This will mean that the state of the peer has been cleaned up (see the “Dynamic Cluster Membership considerations” <a href="https://medium.com/@vaibhavsaini_67863/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-2-4b6f96712bae" data-href="https://medium.com/@vaibhavsaini_67863/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-2-4b6f96712bae" class="markup--anchor markup--li-anchor" target="_blank">here</a>), and the last known <code class="markup--code markup--li-code">cluster.peers</code> have been moved to <code class="markup--code markup--li-code">cluster.bootstrap</code>. When the peer is restarted, it will attempt to rejoin the cluster from which it was removed by using the addresses in <code class="markup--code markup--li-code">cluster.bootstrap</code>.</li></ul><p name="78a8" id="78a8" class="graf graf--p graf-after--li">Remember that a clean peer bootstrapped to an existing cluster will always fetch the latest state. A shutdown-peer which did not leave the cluster will also catch up with the rest of peers after re-starting.</p><p name="d802" id="d802" class="graf graf--p graf-after--p">If the startup initialization fails, <code class="markup--code markup--p-code">ipfs-cluster-service</code> will exit automatically after a few seconds. Pay attention to the INFO and ERROR messages during startup. When ipfs-cluster is ready, a message will indicate it along with a list of peers.</p><h3 name="b1dd" id="b1dd" class="graf graf--h3 graf-after--p">The shared state, the local state and the ipfs state</h3><p name="1b22" id="1b22" class="graf graf--p graf-after--h3">It is important to understand that ipfs-cluster deals with three types of states:</p><ul class="postList"><li name="9aa7" id="9aa7" class="graf graf--li graf-after--p">The <strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">shared state</em></strong> is maintained by the consensus algorithm and a copy is kept in every cluster peer. The shared state stores the list of CIDs which are tracked by ipfs-cluster, their allocations (peers which are pinning them) and their replication factor.</li><li name="cd36" id="cd36" class="graf graf--li graf-after--li">The <strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">local state</em></strong> is maintained separately by every peer and represents the state of CIDs tracked by cluster for that specific peer: status in ipfs (pinned or not), modification time etc.</li><li name="1df3" id="1df3" class="graf graf--li graf-after--li">The <strong class="markup--strong markup--li-strong"><em class="markup--em markup--li-em">ipfs state</em></strong> is the actual state in ipfs (<code class="markup--code markup--li-code">ipfs pin ls</code>) which is maintained by the ipfs daemon.</li></ul><p name="6229" id="6229" class="graf graf--p graf-after--li">In normal operation, all three states are in sync, as updates to the <em class="markup--em markup--p-em">shared state</em> cascade to the local and the ipfs states. Additionally, syncing operations are regularly triggered by ipfs-cluster. Unpinning cluster-pinned items directly from ipfs will, for example, cause a mismatch between the local and the ipfs state. Luckily, there are ways to inspect every state:</p><ul class="postList"><li name="0447" id="0447" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">ipfs-cluster-ctl pin ls</code> shows information about the <em class="markup--em markup--li-em">shared state</em>. The result of this command is produced locally, directly from the state copy stored at the peer.</li><li name="ba3a" id="ba3a" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">ipfs-cluster-ctl status</code> shows information about the <em class="markup--em markup--li-em">local state</em> in every cluster peer. It does so by aggregating local state information received from every cluster member.</li></ul><p name="21d8" id="21d8" class="graf graf--p graf-after--li"><code class="markup--code markup--p-code">ipfs-cluster-ctl sync</code> makes sure that the <em class="markup--em markup--p-em">local state</em> matches the <em class="markup--em markup--p-em">ipfs state</em>. In other words, it makes sure that what cluster expects to be pinned is actually pinned in ipfs. As mentioned, this also happens automatically. Every sync operations triggers an <code class="markup--code markup--p-code">ipfs pin ls --type=recursive</code> call to the local node.</p><p name="6a3a" id="6a3a" class="graf graf--p graf-after--p">Depending on the size of your pinset, you may adjust the interval between the different sync operations using the <code class="markup--code markup--p-code">cluster.state_sync_interval</code> and <code class="markup--code markup--p-code">cluster.ipfs_sync_interval</code> configuration options.</p><p name="ed14" id="ed14" class="graf graf--p graf-after--p graf--trailing">As a final note, the <em class="markup--em markup--p-em">local state</em> may show items in <em class="markup--em markup--p-em">error</em>. This happens when an item took too long to pin/unpin, or the ipfs daemon became unavailable. <code class="markup--code markup--p-code">ipfs-cluster-ctl recover &lt;cid&gt;</code> can be used to rescue these items. See the &quot;Pinning an item&quot; section <a href="https://medium.com/@vaibhavsaini_67863/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-2-4b6f96712bae" data-href="https://medium.com/@vaibhavsaini_67863/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-2-4b6f96712bae" class="markup--anchor markup--p-anchor" target="_blank">in this post</a> for more information.</p></div></div></section><section name="253b" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="9632" id="9632" class="graf graf--p graf--leading">I think you must be exhausted by now, rest for a while. If not you can proceed to next part (explaining different types of clusters, and how to create and maintain them) given below.</p><div name="ab2e" id="ab2e" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-2-4b6f96712bae" data-href="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-2-4b6f96712bae" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-2-4b6f96712bae"><strong class="markup--strong markup--mixtapeEmbed-strong">Setting up your first distributed private storage network on IPFS: Part 2</strong><br><em class="markup--em markup--mixtapeEmbed-em">Welcome back to the IPFS private network series. If you are wondering why I am welcoming you back, then you should take…</em>medium.com</a><a href="https://medium.com/coinmonks/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-2-4b6f96712bae" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="bbc54b1af98b7cbd0c1dc75290c70957" data-thumbnail-img-id="1*ns6pbkuJN3vFMJSqDLDVww.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*ns6pbkuJN3vFMJSqDLDVww.png);"></a></div><h4 name="021e" id="021e" class="graf graf--h4 graf-after--mixtapeEmbed">Learned something? Click the 👏 to say “thanks!” and help others find this article.</h4><p name="1910" id="1910" class="graf graf--p graf-after--h4"><em class="markup--em markup--p-em">Hold down the clap button if you liked the content! It helps me gain exposure .</em></p><p name="76aa" id="76aa" class="graf graf--p graf-after--p">Want to learn more? Checkout my previous articles.</p><div name="3d69" id="3d69" class="graf graf--mixtapeEmbed graf-after--p"><a href="https://hackernoon.com/quantum-computing-is-it-the-end-of-blockchain-9ce4a9664720" data-href="https://hackernoon.com/quantum-computing-is-it-the-end-of-blockchain-9ce4a9664720" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://hackernoon.com/quantum-computing-is-it-the-end-of-blockchain-9ce4a9664720"><strong class="markup--strong markup--mixtapeEmbed-strong">Quantum Computing: Is it the end of blockchain?</strong><br><em class="markup--em markup--mixtapeEmbed-em">Experts are suggesting quantum computing may render blockchain obsolete. As the tech giants such as Google and IBM are…</em>hackernoon.com</a><a href="https://hackernoon.com/quantum-computing-is-it-the-end-of-blockchain-9ce4a9664720" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="0621fabdce44c9b934053355ae4634b2" data-thumbnail-img-id="1*8JzfIkH5mEr0TqAhSMbJkA.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*8JzfIkH5mEr0TqAhSMbJkA.png);"></a></div><div name="04c8" id="04c8" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://hackernoon.com/eos-101-getting-started-with-eos-part-1-ab0324c233e0" data-href="https://hackernoon.com/eos-101-getting-started-with-eos-part-1-ab0324c233e0" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://hackernoon.com/eos-101-getting-started-with-eos-part-1-ab0324c233e0"><strong class="markup--strong markup--mixtapeEmbed-strong">EOS 101: Getting started with EOS, Part 1</strong><br><em class="markup--em markup--mixtapeEmbed-em">The only blockchain which has blocktime of less than a second: 0.5 sec!</em>hackernoon.com</a><a href="https://hackernoon.com/eos-101-getting-started-with-eos-part-1-ab0324c233e0" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="fd8747ef4c18e7ed85fa1f826a789f6f" data-thumbnail-img-id="1*_BKG3utRCovL4A9s78vEpA.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*_BKG3utRCovL4A9s78vEpA.png);"></a></div><div name="7fda" id="7fda" class="graf graf--mixtapeEmbed graf-after--mixtapeEmbed"><a href="https://medium.com/coinmonks/13-sidechain-projects-every-blockchain-developer-should-know-about-804b65364107" data-href="https://medium.com/coinmonks/13-sidechain-projects-every-blockchain-developer-should-know-about-804b65364107" class="markup--anchor markup--mixtapeEmbed-anchor" title="https://medium.com/coinmonks/13-sidechain-projects-every-blockchain-developer-should-know-about-804b65364107"><strong class="markup--strong markup--mixtapeEmbed-strong">13 sidechain projects every blockchain developer should know about</strong><br><em class="markup--em markup--mixtapeEmbed-em">The whole world is going through the blockchain revolution. But wait…is this really what we dreamed of? Present…</em>medium.com</a><a href="https://medium.com/coinmonks/13-sidechain-projects-every-blockchain-developer-should-know-about-804b65364107" class="js-mixtapeImage mixtapeImage u-ignoreBlock" data-media-id="47a933f0a2a854e802a0df436c7a5c2c" data-thumbnail-img-id="1*0lBFcDwvD7ryBTJLSnzYdg.png" style="background-image: url(https://cdn-images-1.medium.com/fit/c/160/160/1*0lBFcDwvD7ryBTJLSnzYdg.png);"></a></div><p name="bc9e" id="bc9e" class="graf graf--p graf-after--mixtapeEmbed graf--trailing"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">Clap 50 times and follow me on Twitter: </em></strong><a href="https://twitter.com/itsmattward" data-href="https://twitter.com/itsmattward" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">@</em></strong></a><a href="https://twitter.com/vasa_develop" data-href="https://twitter.com/vasa_develop" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank"><strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em">vasa_develop</em></strong></a></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@vaibhavsaini_67863" class="p-author h-card">vasa</a> on <a href="https://medium.com/p/a6ff15222b90"><time class="dt-published" datetime="2018-04-24T20:47:16.677Z">April 24, 2018</time></a>.</p><p><a href="https://medium.com/@vaibhavsaini_67863/setting-up-your-first-distributed-private-storage-network-on-ipfs-part-1-a6ff15222b90" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on July 19, 2019.</p></footer></article></body></html>